{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIDtVdjh8CY6FgOnK7iWvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/friedelj/Capstone/blob/main/Capstone_31Categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capstone_31_Categories_1000_Generated_Samples"
      ],
      "metadata": {
        "id": "vYyTJL55eV9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "import random\n",
        "import traceback\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "ILRaWzQYeyN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and output directories\n",
        "input_dir = r'C:\\Users\\josep\\RF Signals'\n",
        "output_dir = r'C:\\Users\\josep\\RF Signals Balanced'\n",
        "target_count = 2000\n",
        "resize_dim = (224, 224)"
      ],
      "metadata": {
        "id": "tZSGFY_dfBml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging\n",
        "failed_images = []"
      ],
      "metadata": {
        "id": "47jKl9dnfG1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Data Augmentation Function ===\n",
        "def augment_image(img):\n",
        "    transformations = [\n",
        "        lambda x: x.rotate(random.uniform(-15, 15)),\n",
        "        lambda x: ImageOps.mirror(x),\n",
        "        # lambda x: ImageOps.flip(x),   # Do not Flip images\n",
        "        lambda x: ImageEnhance.Brightness(x).enhance(random.uniform(0.7, 1.3)),\n",
        "        lambda x: ImageEnhance.Contrast(x).enhance(random.uniform(0.7, 1.3)),\n",
        "    ]\n",
        "    return random.choice(transformations)(img)"
      ],
      "metadata": {
        "id": "cOl-zKBifJ6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Histogram Equalization ===\n",
        "def equalize_histogram(img):\n",
        "    if img.mode != \"RGB\":\n",
        "        img = img.convert(\"RGB\")\n",
        "    r, g, b = img.split()\n",
        "    return Image.merge(\"RGB\", (ImageOps.equalize(r), ImageOps.equalize(g), ImageOps.equalize(b)))"
      ],
      "metadata": {
        "id": "DOfIfY1ofOcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Process Each Class Folder ===\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "BQAOrPJefab-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for class_name in os.listdir(input_dir):\n",
        "    class_path = os.path.join(input_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    print(f'üîç Processing class: {class_name}')\n",
        "    orig_images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    if len(orig_images) == 0:\n",
        "        print(f'‚ö†Ô∏è Skipping {class_name} ‚Äî no images found.')\n",
        "        continue\n",
        "\n",
        "    new_class_path = os.path.join(output_dir, class_name)\n",
        "    os.makedirs(new_class_path, exist_ok=True)\n",
        "    # Copy and standardize up to 2000 original images\n",
        "    copy_count = min(target_count, len(orig_images))\n",
        "    for i in range(copy_count):\n",
        "        try:\n",
        "            orig_name = orig_images[i]\n",
        "            src = os.path.join(class_path, orig_name)\n",
        "            with Image.open(src) as img:\n",
        "                img = img.convert(\"RGB\")\n",
        "                img = img.resize(resize_dim)\n",
        "                img = equalize_histogram(img)\n",
        "                base_name = os.path.splitext(orig_name)[0]\n",
        "                dst = os.path.join(new_class_path, f\"{base_name}.jpg\")\n",
        "                img.save(dst, format='JPEG')\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to process {orig_name} in {class_name}\")\n",
        "            failed_images.append((class_name, orig_name, str(e)))\n",
        "            continue\n",
        "    # Augment if less than 2000 images\n",
        "    current_count = len(os.listdir(new_class_path))\n",
        "    needed = target_count - current_count\n",
        "    if needed > 0:\n",
        "        print(f'‚ûï Augmenting {needed} images for {class_name}')\n",
        "        for i in range(needed):\n",
        "            try:\n",
        "                orig_name = orig_images[i % len(orig_images)]\n",
        "                orig_path = os.path.join(class_path, orig_name)\n",
        "                with Image.open(orig_path) as img:\n",
        "                    img = img.convert(\"RGB\")\n",
        "                    img = augment_image(img)\n",
        "                    img = img.resize(resize_dim)\n",
        "                    img = equalize_histogram(img)\n",
        "                    aug_name = f\"aug_{i}_{os.path.splitext(orig_name)[0]}.jpg\"\n",
        "                    aug_path = os.path.join(new_class_path, aug_name)\n",
        "                    img.save(aug_path, format='JPEG')\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to augment {orig_name} in {class_name}\")\n",
        "                failed_images.append((class_name, orig_name, str(e)))\n",
        "                continue\n",
        "\n",
        "    final_count = len(os.listdir(new_class_path))\n",
        "    print(f'‚úÖ {class_name}: {final_count} images total.')\n",
        "\n",
        "# === Log Any Failures ===\n",
        "if failed_images:\n",
        "    log_path = os.path.join(output_dir, 'failed_images_log.txt')\n",
        "    with open(log_path, 'w') as f:\n",
        "        for entry in failed_images:\n",
        "            f.write(f\"Class: {entry[0]} | File: {entry[1]} | Error: {entry[2]}\\n\")\n",
        "    print(f\"\\n‚ö†Ô∏è Logged {len(failed_images)} failed image(s) to {log_path}\")\n",
        "\n",
        "print(\"\\nüéâ Dataset balancing to 2000 images per class complete.\")"
      ],
      "metadata": {
        "id": "8RZu9Dlsfx2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_dir = r'C:\\Users\\josep\\RF Signals Balanced'\n",
        "\n",
        "# Supported image formats\n",
        "extensions = ('.jpg', '.jpeg', '.png')\n",
        "\n",
        "print(f\"\\nüìä Image counts in each class under: {balanced_dir}\\n\")\n",
        "\n",
        "for class_name in sorted(os.listdir(balanced_dir)):\n",
        "    class_path = os.path.join(balanced_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        files = [f for f in os.listdir(class_path) if f.lower().endswith(extensions)]\n",
        "        count = len(files)\n",
        "        print(f\"{class_name:35} {count:5} images\")"
      ],
      "metadata": {
        "id": "kfqHHRjEf5UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the balanced image dataset\n",
        "balanced_dir = r'C:\\Users\\josep\\RF Signals Balanced'\n",
        "\n",
        "# Modulation mapping\n",
        "modulation_map = {\n",
        "    \"16QAM\": 1, \"2ASK\": 2, \"32QAM\": 3, \"4FSK\": 4, \"8PSK\": 5, \"RS41-Radiosonde\": 6,\n",
        "    \"Radioteletype\": 7, \"ads-b\": 8, \"airband\": 9, \"ais\": 10, \"am\": 11, \"atsc\": 12,\n",
        "    \"automatic-picture-transmission\": 13, \"bluetooth\": 14, \"cellular\": 15,\n",
        "    \"digital-audio-broadcasting\": 16, \"digital-speech-decoder\": 17, \"drone-video\": 18,\n",
        "    \"fm\": 19, \"hdmi\": 20, \"lora\": 21, \"morse\": 22, \"on-off-keying\": 23, \"packet\": 24,\n",
        "    \"pocsag\": 25, \"remote-keyless-entry\": 26, \"sstv\": 27, \"uav-video\": 28,\n",
        "    \"vor\": 29, \"wifi\": 30, \"z-wave\": 31\n",
        "}\n",
        "\n",
        "# Initialize rows for the dataframe\n",
        "rows = []\n",
        "line_number = 1\n",
        "\n",
        "# Walk through each class directory\n",
        "for class_name, class_number in modulation_map.items():\n",
        "    class_dir = os.path.join(balanced_dir, class_name)\n",
        "    if not os.path.isdir(class_dir):\n",
        "        print(f\"‚ö†Ô∏è Skipping missing folder: {class_dir}\")\n",
        "        continue\n",
        "\n",
        "    for file in sorted(os.listdir(class_dir)):\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            file_path = os.path.join(class_name, file)  # relative path\n",
        "            rows.append({\n",
        "                \"Line Number\": line_number,\n",
        "                \"Modulation Type\": class_number,\n",
        "                \"Image File\": file_path\n",
        "            })\n",
        "            line_number += 1\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(rows, columns=[\"Line Number\", \"Modulation Type\", \"Image File\"])\n",
        "\n",
        "# Save to CSV\n",
        "csv_path = os.path.join(balanced_dir, \"modulation_dataset_index.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ DataFrame created with {len(df)} entries.\")\n",
        "print(f\"üìÑ CSV saved to: {csv_path}\")"
      ],
      "metadata": {
        "id": "w895kAfof-sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path"
      ],
      "metadata": {
        "id": "KnTMGQ6zgDmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "eyDtHTI0gGOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove exact duplicates based on 'Image File'\n",
        "df_cleaned = df.drop_duplicates(subset=[\"Image File\"]).reset_index(drop=True)\n",
        "\n",
        "# Show how many were removed\n",
        "removed = len(df) - len(df_cleaned)\n",
        "print(f\"‚úÖ Removed {removed} duplicate image entries.\")\n",
        "print(f\"üìä Cleaned DataFrame now has {len(df_cleaned)} unique images.\")\n",
        "\n",
        "# Show first 5 rows\n",
        "print(df_cleaned.head())"
      ],
      "metadata": {
        "id": "mNysCvR_gJPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a 'Base Name' column (filename without extension)\n",
        "df['Base Name'] = df['Image File'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
        "df['Extension'] = df['Image File'].apply(lambda x: os.path.splitext(x)[1].lower())\n",
        "\n",
        "# Sort so PNG comes after JPG\n",
        "df_sorted = df.sort_values(by=['Base Name', 'Extension'], ascending=[True, False])\n",
        "\n",
        "# Drop duplicates based on 'Base Name', keeping the .png version\n",
        "df_deduped = df_sorted.drop_duplicates(subset=['Base Name'], keep='first').reset_index(drop=True)\n",
        "\n",
        "# Drop helper columns\n",
        "df_deduped = df_deduped.drop(columns=['Base Name', 'Extension'])\n",
        "\n",
        "# Reassign new line numbers\n",
        "df_deduped['Line Number'] = range(1, len(df_deduped) + 1)\n",
        "\n",
        "# Save to CSV\n",
        "csv_path = os.path.join(balanced_dir, \"modulation_dataset_index_nodupes.csv\")\n",
        "df_deduped.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Removed .jpg duplicates ‚Äî only .png versions retained when both exist.\")\n",
        "print(f\"üìä Final count: {len(df_deduped)} unique image entries.\")"
      ],
      "metadata": {
        "id": "3lfxPC1PgQoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Modulation Type' and count entries\n",
        "modulation_counts = df_deduped.groupby('Modulation Type')['Image File'].count()\n",
        "\n",
        "# Display the counts\n",
        "print(modulation_counts.sort_index())"
      ],
      "metadata": {
        "id": "RKTyUQqbgVun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first 5 rows\n",
        "print(df_deduped.head())"
      ],
      "metadata": {
        "id": "wo8XVd3PgczR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map numbers back to names\n",
        "modulation_name_map = {\n",
        "    1: \"16QAM\", 2: \"2ASK\", 3: \"32QAM\", 4: \"4FSK\", 5: \"8PSK\", 6: \"RS41-Radiosonde\",\n",
        "    7: \"Radioteletype\", 8: \"ads-b\", 9: \"airband\", 10: \"ais\", 11: \"am\", 12: \"atsc\",\n",
        "    13: \"automatic-picture-transmission\", 14: \"bluetooth\", 15: \"cellular\",\n",
        "    16: \"digital-audio-broadcasting\", 17: \"digital-speech-decoder\", 18: \"drone-video\",\n",
        "    19: \"fm\", 20: \"hdmi\", 21: \"lora\", 22: \"morse\", 23: \"on-off-keying\", 24: \"packet\",\n",
        "    25: \"pocsag\", 26: \"remote-keyless-entry\", 27: \"sstv\", 28: \"uav-video\",\n",
        "    29: \"vor\", 30: \"wifi\", 31: \"z-wave\"\n",
        "}\n",
        "\n",
        "# Convert Series to DataFrame for better formatting\n",
        "modulation_counts_df = modulation_counts.reset_index()\n",
        "modulation_counts_df['Modulation Name'] = modulation_counts_df['Modulation Type'].map(modulation_name_map)\n",
        "\n",
        "# Reorder columns\n",
        "modulation_counts_df = modulation_counts_df[['Modulation Type', 'Modulation Name', 'Image File']]\n",
        "modulation_counts_df.columns = ['Modulation Type', 'Modulation Name', 'Image Count']\n",
        "\n",
        "# Sort and display\n",
        "print(modulation_counts_df.sort_values(by='Modulation Type'))"
      ],
      "metadata": {
        "id": "8-b9q4sqgg7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Modulation Type' and count image files\n",
        "modulation_counts = df_deduped.groupby('Modulation Type')['Image File'].count()\n",
        "\n",
        "# Define mapping from modulation type number to name\n",
        "modulation_name_map = {\n",
        "    1: \"16QAM\", 2: \"2ASK\", 3: \"32QAM\", 4: \"4FSK\", 5: \"8PSK\", 6: \"RS41-Radiosonde\",\n",
        "    7: \"Radioteletype\", 8: \"ads-b\", 9: \"airband\", 10: \"ais\", 11: \"am\", 12: \"atsc\",\n",
        "    13: \"automatic-picture-transmission\", 14: \"bluetooth\", 15: \"cellular\",\n",
        "    16: \"digital-audio-broadcasting\", 17: \"digital-speech-decoder\", 18: \"drone-video\",\n",
        "    19: \"fm\", 20: \"hdmi\", 21: \"lora\", 22: \"morse\", 23: \"on-off-keying\", 24: \"packet\",\n",
        "    25: \"pocsag\", 26: \"remote-keyless-entry\", 27: \"sstv\", 28: \"uav-video\",\n",
        "    29: \"vor\", 30: \"wifi\", 31: \"z-wave\"\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "modulation_counts_df = modulation_counts.reset_index()\n",
        "modulation_counts_df['Modulation Name'] = modulation_counts_df['Modulation Type'].map(modulation_name_map)\n",
        "modulation_counts_df.columns = ['Modulation Type', 'Image Count', 'Modulation Name']\n",
        "modulation_counts_df = modulation_counts_df[['Modulation Type', 'Modulation Name', 'Image Count']]\n",
        "\n",
        "# Save to CSV\n",
        "csv_output_path = os.path.join(balanced_dir, \"modulation_image_counts.csv\")\n",
        "modulation_counts_df.to_csv(csv_output_path, index=False)\n",
        "print(f\"‚úÖ CSV saved to: {csv_output_path}\")\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.bar(modulation_counts_df['Modulation Name'], modulation_counts_df['Image Count'], color='steelblue')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Image Count per Modulation Type\")\n",
        "plt.xlabel(\"Modulation Type\")\n",
        "plt.ylabel(\"Image Count\")\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uxZ7ICszgklL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first 5 rows\n",
        "print(modulation_counts_df.head(31))"
      ],
      "metadata": {
        "id": "-UEzAkVEgwg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column that marks whether the image was augmented or original\n",
        "df_deduped['Augmented'] = df_deduped['Image File'].apply(lambda x: os.path.basename(x).startswith('aug_'))\n",
        "\n",
        "# Optional: Count how many are augmented vs original\n",
        "print(df_deduped['Augmented'].value_counts())"
      ],
      "metadata": {
        "id": "fOpmFqJugzdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first 5 rows\n",
        "print(df_deduped.head())"
      ],
      "metadata": {
        "id": "FeQ6M4o1g4yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_signals = df_deduped"
      ],
      "metadata": {
        "id": "_z9dzD0Yg-Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df_signals.corr(numeric_only=True)\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "id": "2e0Qvsq1g_Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_signals.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix of df_signals\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MBiMo8DshJ9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute correlation matrix (only for numeric columns)\n",
        "corr_matrix = df_signals.corr(numeric_only=True)\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt=\".2f\", linewidths=0.5, square=True)\n",
        "\n",
        "# Add title and layout\n",
        "plt.title(\"Correlation Matrix of df_signals\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mUPHuBy1hL1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the summary table\n",
        "summary = df_signals.groupby(['Modulation Type', 'Augmented'])['Image File'].count().unstack(fill_value=0)\n",
        "summary.columns = ['Original Images', 'Augmented Images']\n",
        "summary['Total Images'] = summary['Original Images'] + summary['Augmented Images']\n",
        "summary = summary.reset_index()\n",
        "\n",
        "# Add modulation names (if you have a mapping)\n",
        "modulation_name_map = {\n",
        "    1: \"16QAM\", 2: \"2ASK\", 3: \"32QAM\", 4: \"4FSK\", 5: \"8PSK\", 6: \"RS41-Radiosonde\",\n",
        "    7: \"Radioteletype\", 8: \"ads-b\", 9: \"airband\", 10: \"ais\", 11: \"am\", 12: \"atsc\",\n",
        "    13: \"automatic-picture-transmission\", 14: \"bluetooth\", 15: \"cellular\",\n",
        "    16: \"digital-audio-broadcasting\", 17: \"digital-speech-decoder\", 18: \"drone-video\",\n",
        "    19: \"fm\", 20: \"hdmi\", 21: \"lora\", 22: \"morse\", 23: \"on-off-keying\", 24: \"packet\",\n",
        "    25: \"pocsag\", 26: \"remote-keyless-entry\", 27: \"sstv\", 28: \"uav-video\",\n",
        "    29: \"vor\", 30: \"wifi\", 31: \"z-wave\"\n",
        "}\n",
        "summary['Modulation Name'] = summary['Modulation Type'].map(modulation_name_map)\n",
        "summary = summary[['Modulation Type', 'Modulation Name', 'Original Images', 'Augmented Images', 'Total Images']]\n",
        "\n",
        "# Display the table\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "8Ctm_o5DhSq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar chart\n",
        "plt.figure(figsize=(14, 7))\n",
        "bar_width = 0.35\n",
        "x = range(len(summary))\n",
        "\n",
        "plt.bar(x, summary['Original Images'], width=bar_width, label='Original', color='steelblue')\n",
        "plt.bar([i + bar_width for i in x], summary['Augmented Images'], width=bar_width, label='Augmented', color='salmon')\n",
        "\n",
        "plt.xlabel('Modulation Type')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Original vs Augmented Image Counts by Modulation Type')\n",
        "plt.xticks([i + bar_width / 2 for i in x], summary['Modulation Name'], rotation=90)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wjowUnQfhbAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by modulation name (optional, for readability)\n",
        "summary_sorted = summary.sort_values(\"Modulation Name\")\n",
        "\n",
        "# Set up the plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Plot stacked bars: Original + Augmented\n",
        "plt.bar(summary_sorted['Modulation Name'], summary_sorted['Original Images'],\n",
        "        label='Original', color='steelblue')\n",
        "plt.bar(summary_sorted['Modulation Name'], summary_sorted['Augmented Images'],\n",
        "        bottom=summary_sorted['Original Images'], label='Augmented', color='salmon')\n",
        "\n",
        "# Plot Total as black dots (optional)\n",
        "plt.plot(summary_sorted['Modulation Name'], summary_sorted['Total Images'],\n",
        "         marker='o', color='black', linestyle='None', label='Total')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Modulation Type')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Image Count per Modulation Type (Original + Augmented)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_1wFUrV-hjWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by modulation type and augmentation status\n",
        "summary_table = df_signals.groupby(['Modulation Type', 'Augmented'])['Image File'].count().unstack(fill_value=0)\n",
        "\n",
        "# Rename columns for clarity\n",
        "summary_table.columns = ['Original Images', 'Augmented Images']\n",
        "\n",
        "# Add total column\n",
        "summary_table['Total Images'] = summary_table['Original Images'] + summary_table['Augmented Images']\n",
        "\n",
        "# Calculate Original_Percentage\n",
        "summary_table['Original_Percentage'] = summary_table['Original Images'] / summary_table['Total Images'] * 100\n",
        "\n",
        "# Reset index to make 'Modulation Type' a column\n",
        "summary_table = summary_table.reset_index()\n",
        "\n",
        "# Add modulation name mapping\n",
        "modulation_name_map = {\n",
        "    1: \"16QAM\", 2: \"2ASK\", 3: \"32QAM\", 4: \"4FSK\", 5: \"8PSK\", 6: \"RS41-Radiosonde\",\n",
        "    7: \"Radioteletype\", 8: \"ads-b\", 9: \"airband\", 10: \"ais\", 11: \"am\", 12: \"atsc\",\n",
        "    13: \"automatic-picture-transmission\", 14: \"bluetooth\", 15: \"cellular\",\n",
        "    16: \"digital-audio-broadcasting\", 17: \"digital-speech-decoder\", 18: \"drone-video\",\n",
        "    19: \"fm\", 20: \"hdmi\", 21: \"lora\", 22: \"morse\", 23: \"on-off-keying\", 24: \"packet\",\n",
        "    25: \"pocsag\", 26: \"remote-keyless-entry\", 27: \"sstv\", 28: \"uav-video\",\n",
        "    29: \"vor\", 30: \"wifi\", 31: \"z-wave\"\n",
        "}\n",
        "summary_table['Modulation Name'] = summary_table['Modulation Type'].map(modulation_name_map)\n",
        "\n",
        "# Rearrange columns\n",
        "summary_table = summary_table[['Modulation Type', 'Modulation Name',\n",
        "                               'Original Images', 'Augmented Images',\n",
        "                               'Total Images', 'Original_Percentage']]\n",
        "\n",
        "# Display the table\n",
        "print(summary_table)"
      ],
      "metadata": {
        "id": "AdhusMLvhoD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort for cleaner x-axis display\n",
        "summary_sorted = summary_table.sort_values(\"Modulation Name\")\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(summary_sorted['Modulation Name'], summary_sorted['Original Images'],\n",
        "         marker='o', label='Original Images', color='steelblue')\n",
        "plt.plot(summary_sorted['Modulation Name'], summary_sorted['Augmented Images'],\n",
        "         marker='s', label='Augmented Images', color='salmon')\n",
        "plt.plot(summary_sorted['Modulation Name'], summary_sorted['Total Images'],\n",
        "         marker='^', label='Total Images', color='green')\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Modulation Type')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Image Distribution per Modulation Type')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wIDjGzGJhwaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of Image Counts per Modulation (Distribution)\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.histplot(data=summary_table, x='Total Images', bins=20, kde=True)\n",
        "plt.title('Histogram of Total Image Counts per Modulation Type')\n",
        "plt.xlabel('Number of Images')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wVWMC0_Kh1b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box Plot of Image Counts\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(data=summary_table[['Original Images', 'Augmented Images']])\n",
        "plt.title('Box Plot of Image Counts')\n",
        "plt.ylabel('Image Count')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VNMomlSgh9wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar Chart of Top N Modulation Types by Image Count\n",
        "top_n = summary_table.sort_values('Total Images', ascending=False).head(10)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x='Modulation Name', y='Total Images', data=top_n, palette='viridis')\n",
        "plt.title('Top 10 Modulation Types by Total Image Count')\n",
        "plt.ylabel('Total Images')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s3xZTlv7iBQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first 5 rows\n",
        "print(df_signals.head())"
      ],
      "metadata": {
        "id": "NgPf2goyiHhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Neural Network"
      ],
      "metadata": {
        "id": "G6M57064iMFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_signals.to_csv(\"df_signals.csv\", index=False)"
      ],
      "metadata": {
        "id": "hk-DzDYyiJRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PARAMETERS ===\n",
        "data_dir = r\"C:\\Users\\josep\\RF Signals Balanced\"\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "FUW46LkliUYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === LOAD DATASETS ===\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "9GuFAsjMiaFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === GET CLASS NAMES ===\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(f\"Classes: {class_names}\")"
      ],
      "metadata": {
        "id": "N_VWxuKZieFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total number of batches\n",
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "\n",
        "# Take the first half as validation\n",
        "new_val_ds = val_ds.take(val_batches // 2)\n",
        "\n",
        "# Take the second half as test\n",
        "test_ds = val_ds.skip(val_batches // 2)"
      ],
      "metadata": {
        "id": "3XAS9BJTihUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PERFORMANCE ===\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "KFNDlXrEilO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === BUILD CNN MODEL ===\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=img_size + (3,)),\n",
        "    layers.Rescaling(1./255),\n",
        "\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "l2zX2b8giojj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "wchbguPZiqzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, epochs=10)"
      ],
      "metadata": {
        "id": "gyFUOOwPiuS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === EVALUATE ===\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "5dB45qQ8izfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Generate predictions on test set ===\n",
        "y_true = []\n",
        "y_pred = []"
      ],
      "metadata": {
        "id": "vBKyMrkDi5fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in test_ds:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))"
      ],
      "metadata": {
        "id": "lIjapKNEi8iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)"
      ],
      "metadata": {
        "id": "8aqTHEj0jBSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Confusion Matrix ===\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_labels = class_names  # from earlier in your script"
      ],
      "metadata": {
        "id": "gP2SwJyxjFiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize by row (i.e., true class counts)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
      ],
      "metadata": {
        "id": "4_kiwV4CjJme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Plot Confusion Matrix ===\n",
        "plt.figure(figsize=(18, 14))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.title('Normalized Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Y7dyQ94jNR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Per-Class Accuracy ===\n",
        "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(x=class_labels, y=per_class_accuracy)\n",
        "plt.title('Per-Class Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R1LoG5KYjRCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Display classification report ===\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "tffhb5U9jWuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PLOT ACCURACY ===\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CiVeOGbNjZ7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}